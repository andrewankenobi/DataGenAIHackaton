# K-means and LLMs

The SQL script provides a detailed methodology for leveraging a Large Language Model (LLM) in tandem with Google BigQuery for the purpose of analyzing and segmenting customer data using unsupervised machine learning. 

## Preparing the environment

### Prerequisites
- Create a BigQuery dataset > variable <YourDataset>

- Upload the content of the provided [`crm_account.csv`](https://github.com/andrewankenobi/CustomerInsightAI/blob/main/crm_account) in a BigQuery table of choice > variable <YourBaseTable>
- Create an external connection to invoke a remote AI model (text-bison) > see https://cloud.google.com/bigquery/docs/generate-text#create_a_connection 
- Assign to the service account associated with the external connection the Vertex AI User role > https://cloud.google.com/bigquery/docs/generate-text#give_the_service_account_access 

- In [`Setup.sql`](https://github.com/andrewankenobi/CustomerInsightAI/blob/main/Setup.sql), change <YourDataset> with the name of your dataset (find/replace)
- In [`Setup.sql`](https://github.com/andrewankenobi/CustomerInsightAI/blob/main/Setup.sql), change <YourBaseTable> with the name of the table in which you uploded the demo data (find/replace)
- In [`Setup.sql`](https://github.com/andrewankenobi/CustomerInsightAI/blob/main/Setup.sql), change <YourConnection> with the name of the External Connection you configured for BigQuery (find/replace)

Once the prequisites are met, run the customized [`Setup.sql`](https://github.com/andrewankenobi/CustomerInsightAI/blob/main/Setup.sql). Below an explanation of the deployment steps:

### Instantiate LLM leveraging text-bison (waiting for Gemini on BQML)
- **Purpose**: Creates a new model named `llm` using a remote connection (`us-central1.llm`) with the endpoint set to `text-bison`. This model facilitates text generation through the LLM.

### Create a Model k-Means
- **Details**: Constructs a k-means clustering model named `account_groups`, utilizing data from the `crm_account` table within the `Landing` dataset. This model is designed to segment customer data into distinct clusters.

### Create a view with group ID predictions
- **Functionality**: Generates a view named `account_predicted_groups`. This view displays the outcomes of applying the k-means model to forecast cluster groups for each account, specifically excluding the distance to the nearest centroids.

### Create a flattened version for LLM inference (Predicted Groups)
- **Implementation**: Forms a view called `account_predicted_groups_flattened` that compiles the predicted group data into a JSON array format. This process selects a random sample of the data with a 1% probability.

### Create a flattened version for LLM inference (CRM Account)
- **Procedure**: Similar to the prior step, this view, named `crm_account_flattened`, converts all data from the `crm_account` table into a flattened JSON array, also employing random sampling of the data (1.5% probability).

### Create LLM-driven column descriptions
- **Outcome**: A table named `llm_columns_description` is created to store outputs from the LLM model. These outputs describe each column of the `crm_account` table in a key-value format, achieved by prompting the LLM with data compiled from `crm_account_flattened`.

### Create a LLM-single inference for group descriptions
- **Overview**: Establishes a view named `llm_groups_description` to contain descriptions of customer groups as generated by the LLM. This view utilizes a prompt that merges column descriptions with customer segment data, aiming to delineate the characteristics of each customer group.

### Create a table for intermediate results
- **Function**: Sets up a table named `analysis_results` to record the epochs and group descriptions generated by the LLM. This table serves to accumulate results from multiple model executions.

### Stored procedure for data insertion
- **Method**: Introduces a stored procedure named `insert_descriptions_n_times` to repeatedly populate the `analysis_results` table with descriptions from the `llm_groups_description` view, ensuring the freshness of data by truncating the table prior to each insertion.

### Create a view for multi-description aggregation
- **Capability**: The view `llm_group_description_multi` consolidates various interpretations of customer group data into a singular, comprehensive description for each group, as formulated by the LLM. This consolidation is achieved by summarizing the most pertinent inputs from the `analysis_results` table and crafting a new LLM prompt.

This script exploits advanced BigQuery capabilities alongside the analytical power of LLM to dissect, segment, and articulate customer data. It delivers profound insights into customer behavior and traits through clustering and natural language processing.

## Running the demo

### Prerequisites
- Set up the environment as specified above
- In [`Demo.sql`](https://github.com/andrewankenobi/CustomerInsightAI/blob/main/Demo.sql), change <YourDataset> with the name of your dataset (find/replace)
- [`Demo.sql`](https://github.com/andrewankenobi/CustomerInsightAI/blob/main/Demo.sql), change <YourBaseTable> with the name of the table in which you uploded the demo data (find/replace)

You now can run the demo using the customized [`Demo.sql`](https://github.com/andrewankenobi/CustomerInsightAI/blob/main/Demo.sql).

Below an explanation of the demo steps. 

### Start with the base data
Selects a random sample (1.5%) from the `crm_account` table in the `Landing` dataset. This serves as the foundational data set for further analysis.

### See the predicted Customer Groups
Queries the Landing.account_predicted_groups view to fetch a random sample (1.5%) of the predicted customer groupings from the k-means clustering model, excluding distances to centroids.

### Use GenAI to infer the content of all columns (single shot)
Retrieves descriptions for each column in the dataset, generated by a GenAI model based on a subset of the data (1%)

### Infer what the Centroids describe (single shot)
Selects descriptions for what each centroid (cluster center) represents, according to the GenAI's interpretation of the clustered data, for only a small subset of data (1%)

### Multi-shot analysis
Executes the insert_descriptions_n_times stored procedure with 20 as an argument (aiming at analyzing roughly 20% of all available samples), which populates the Landing.analysis_results table with multiple interpretations of group descriptions.

### Inspect the table
Orders and displays the content of the Landing.analysis_results table to examine the variance in outcomes across different epochs.

### Run a LLM inference on the multi-shotted data
Aggregates data from the Landing.analysis_results into a JSON array and utilizes the GenAI model to generate summarized descriptions of customer groups.

### Validation 
Randomly selects a subset of data from the Landing.account_predicted_groups to compare and contrast against the GenAI's interpretations, ensuring the analysis makes sense.

## Something for your mood
Why did the data analyst break up with Google BigQuery?
Because every time they said "Let's get closer," BigQuery kept increasing the distance to the nearest centroid!

